<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Girlden&#39;s Blog</title>
  
  <subtitle>Quick notes</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-03-31T02:48:51.347Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Girlden</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>数据分析师的面试准备</title>
    <link href="http://yoursite.com/2018/03/31/%E9%9D%A2%E8%AF%95/"/>
    <id>http://yoursite.com/2018/03/31/面试/</id>
    <published>2018-03-31T02:14:58.000Z</published>
    <updated>2018-03-31T02:48:51.347Z</updated>
    
    <content type="html"><![CDATA[<p>我觉得自己既然选择放弃考研，转而找工作就应该有找工作应该有的态度。至少我不想自己未来后悔，无论未来找不找的到，起码这篇长文应该能说明一切。我可以承受失败，但我不能接受自己坐以待毙，不努力后的失败。<br>下面开始我的正文。</p><p>我找的是数据分析岗，截至目前2018年3月31日，我看到的国内的大公司，包括BAT,网易，头条，七牛云，京东，小米，岗位主要分布在技术岗，产品运营岗，产品设计岗这三个岗位。</p><h1 id="浅尝笔试："><a href="#浅尝笔试：" class="headerlink" title="浅尝笔试："></a>浅尝笔试：</h1><ul><li>第一家的腾讯模拟笔试，笔试很基础，但是你乍一眼看上去就是很难，比如，他会考你相关关系和因果关系的区别（这道题分很高），还有排列组合，二叉树的前中后序遍历，SQL语句，以及统计的基础内容。</li><li>第二家的网易实习笔试，题目开始有难度，不过这些难度都是虚的，20题选择，3题问答，20题的部分主要看个人能力，当然也有数据分析相关的统计和数据结构。3题问答就是数据分析的基本功了，要会sql的高级查询，一定要到网站上刷题！！！还有就是一些用户特征分析的操作，我觉得可以在日常就留给心眼，做在脑中呈现完整的数据分析过程，遇到这种问题就能得心应手。</li></ul><p>经过这两门的笔试，我有了些自己的感悟：</p><ul><li>不要只注重刷死题，数据分析本来就是一个注重分析的岗位，大学里应付期末考试的那套方法在这里不灵，我们要做的就是多看，看图表；多思，思业务和技术的联系；多总结，业务难点。</li><li>基础知识必须夯实，统计，sql或者excel，Python或者R，机器学习算法，和业务相关的经济知识。</li><li>看公司都有什么样的业务，对应会出现什么业务需求，不同的业务需求要有什么的对策，要用什么样的分析方法。</li></ul><p>2018/3/31 10:40:38 </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;我觉得自己既然选择放弃考研，转而找工作就应该有找工作应该有的态度。至少我不想自己未来后悔，无论未来找不找的到，起码这篇长文应该能说明一切。我可以承受失败，但我不能接受自己坐以待毙，不努力后的失败。&lt;br&gt;下面开始我的正文。&lt;/p&gt;
&lt;p&gt;我找的是数据分析岗，截至目前2018
      
    
    </summary>
    
      <category term="数据分析职业" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%81%8C%E4%B8%9A/"/>
    
    
      <category term="面试或笔试" scheme="http://yoursite.com/tags/%E9%9D%A2%E8%AF%95%E6%88%96%E7%AC%94%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>python3和Python2的区别</title>
    <link href="http://yoursite.com/2018/03/08/python3%E5%92%8CPython2%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>http://yoursite.com/2018/03/08/python3和Python2的区别/</id>
    <published>2018-03-08T05:18:02.000Z</published>
    <updated>2018-03-08T05:40:49.446Z</updated>
    
    <content type="html"><![CDATA[<p>小编在学习apriori算法的时候，发现了一些Python两种版本的差别，虽然不大，但是还是记下来比较好，万一以后要用也好找，毕竟python3在未来还是会取代python2的，但是学习的时候还是python2比较稳定。</p><h1 id="字典dict的has-key"><a href="#字典dict的has-key" class="headerlink" title="字典dict的has_key()"></a>字典dict的has_key()</h1><p>python3中已经不用这个方法了。<br><figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dict_1 = &#123;k:<span class="string">'g'</span>, e:<span class="string">'h'</span>, y:<span class="string">'j'</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#对于py2</span></span><br><span class="line"><span class="keyword">if</span> dict_1.has_key(k):</span><br><span class="line"></span><br><span class="line"><span class="meta">#对于py3</span></span><br><span class="line"><span class="keyword">if</span> k in dict_1:</span><br></pre></td></tr></table></figure></p><h1 id="内建函数map"><a href="#内建函数map" class="headerlink" title="内建函数map()"></a>内建函数map()</h1><p>py3中无法返回list<br><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#py2中直接返回<span class="built_in">list</span></span><br><span class="line">len(<span class="built_in">map</span>对象)</span><br><span class="line"></span><br><span class="line">#py3需要进行一次转换</span><br><span class="line">len(<span class="built_in">list</span>(<span class="built_in">map</span>对象))</span><br></pre></td></tr></table></figure></p><p>2018/3/8 13:35:12 </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;小编在学习apriori算法的时候，发现了一些Python两种版本的差别，虽然不大，但是还是记下来比较好，万一以后要用也好找，毕竟python3在未来还是会取代python2的，但是学习的时候还是python2比较稳定。&lt;/p&gt;
&lt;h1 id=&quot;字典dict的has-key
      
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="python版本区别" scheme="http://yoursite.com/tags/python%E7%89%88%E6%9C%AC%E5%8C%BA%E5%88%AB/"/>
    
  </entry>
  
  <entry>
    <title>数据库与数据对象</title>
    <link href="http://yoursite.com/2018/03/02/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E6%93%8D%E4%BD%9C/"/>
    <id>http://yoursite.com/2018/03/02/数据库的操作/</id>
    <published>2018-03-02T04:22:28.000Z</published>
    <updated>2018-03-07T10:07:55.045Z</updated>
    
    <content type="html"><![CDATA[<h1 id="创建和维护数据库"><a href="#创建和维护数据库" class="headerlink" title="创建和维护数据库"></a>创建和维护数据库</h1><p>数据库中的一些概念之间的关系如以下的思维导图：<br><img src="https://i.imgur.com/01i4d9q.png" alt=""></p><h2 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h2><p>创建数据库需要注意一下的几个步骤：</p><ol><li>注明<strong>数据库的名称</strong>。</li><li>看清有几个<strong>数据文件</strong>，<strong>日志文件</strong>。</li><li>数据文件是否需要有<strong>文件组</strong>的安排。</li><li>初始化文件的各种属性。</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> 数据库名称</span><br><span class="line"><span class="keyword">ON</span> PRIMARY</span><br><span class="line">   (<span class="keyword">NAME</span> = 逻辑文件名</span><br><span class="line">    FILENAME = 物理文件名</span><br><span class="line">    <span class="keyword">SIZE</span> = 初始大小</span><br><span class="line">    <span class="keyword">MAXSIZE</span> = 最大大小</span><br><span class="line">FILEGROWTH = 增长</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">FILEGROUP 用户自定义的文件组名</span><br><span class="line">(<span class="keyword">NAME</span> = 逻辑文件名</span><br><span class="line">    FILENAME = 物理文件名</span><br><span class="line">    <span class="keyword">SIZE</span> = 初始大小</span><br><span class="line">    <span class="keyword">MAXSIZE</span> = 最大大小</span><br><span class="line">FILEGROWTH = 增长</span><br><span class="line">    )</span><br><span class="line"><span class="keyword">LOG</span> <span class="keyword">ON</span></span><br><span class="line">(<span class="keyword">NAME</span> = 逻辑文件名</span><br><span class="line">    FILENAME = 物理文件名</span><br><span class="line">    <span class="keyword">SIZE</span> = 初始大小</span><br><span class="line">    <span class="keyword">MAXSIZE</span> = 最大大小</span><br><span class="line">FILEGROWTH = 增长</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><h2 id="修改数据库"><a href="#修改数据库" class="headerlink" title="修改数据库"></a>修改数据库</h2><h3 id="扩大数据库空间"><a href="#扩大数据库空间" class="headerlink" title="扩大数据库空间"></a>扩大数据库空间</h3><p>如果没有设置数据库自动增长的话，那么数据库在使用一段时间后会出现空间不够的情况，那么就可以通过修改数据库空间来解决。</p><p>扩大数据库空间有两个方法：</p><ol><li>扩大已有文件的大小。</li><li>数据库添加新的文件。</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">DATABASE</span> 数据库的名称</span><br><span class="line">#<span class="keyword">ADD</span> <span class="keyword">FILE</span></span><br><span class="line">(<span class="keyword">NAME</span> = 逻辑文件名</span><br><span class="line">    FILENAME = 物理文件名</span><br><span class="line">    <span class="keyword">SIZE</span> = 初始大小</span><br><span class="line">    <span class="keyword">MAXSIZE</span> = 最大大小</span><br><span class="line">FILEGROWTH = 增长</span><br><span class="line">    )</span><br><span class="line">#<span class="keyword">MODIFY</span> <span class="keyword">FILE</span></span><br><span class="line">(<span class="keyword">NAME</span> = 逻辑文件名</span><br><span class="line">    <span class="keyword">SIZE</span> = 初始大小</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><p>注意：增加文件还可以讲文件添加到指定的文件组组中。</p><h3 id="收缩数据文件"><a href="#收缩数据文件" class="headerlink" title="收缩数据文件"></a>收缩数据文件</h3><p>释放文件中未使用的空间，并将此空间还给系统空间，数据文件和日志文件都可以收缩。<br>收缩的方法有：</p><ol><li>手动收缩</li><li>设置数据库参数自动收缩</li></ol><h4 id="手动收缩"><a href="#手动收缩" class="headerlink" title="手动收缩"></a>手动收缩</h4><ol><li><p>收缩整个数据库的大小。</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DBBC <span class="keyword">SHRINKDATABASE</span></span><br><span class="line"><span class="keyword"></span>(数据库名称或者ID，</span><br><span class="line">     大小比例,</span><br><span class="line">     NOTRUNCATE或者TRUNCATEONLY) <span class="comment">#要么把空间给系统，要么不保留</span></span><br></pre></td></tr></table></figure></li><li><p>收缩指定文件的大小</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DBBC <span class="keyword">SHRINKDATABASE</span></span><br><span class="line"><span class="keyword"></span>(数据库名称或者ID，</span><br><span class="line">     大小比例,</span><br><span class="line">     EMPTYFILE, <span class="comment">#该文件为空，将原有文件转移到同一文件组的其他文件中。</span></span><br><span class="line">     NOTRUNCATE或者TRUNCATEONLY)</span><br></pre></td></tr></table></figure></li></ol><h4 id="自动收缩"><a href="#自动收缩" class="headerlink" title="自动收缩"></a>自动收缩</h4><p>就是简单的将数据库的<code>AUTO_SHRINK</code>设置为True，默认情况下是False。</p><h3 id="添加和删除数据库文件"><a href="#添加和删除数据库文件" class="headerlink" title="添加和删除数据库文件"></a>添加和删除数据库文件</h3><p>可以通过在数据库中添加文件来扩大数据库的大小，也可以通过删除数据库的文件来减小数据库的大小。</p><h4 id="添加"><a href="#添加" class="headerlink" title="添加"></a>添加</h4><p>文件组中各个文件的数据量大小就是和和文件的可用空间成正比，所以添加数据文件的时候数据库会先使用新加的文件。相比之下，日志文件就不会这样，由于文件不存在文件组，所以文件之间是彼此独立，总是先写第一个日志文件，当填充满了以后再写第二个，所以，当添加日志文件的时候不会立刻使用该文件，直到其他文件被填满。</p><h4 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h4><p>只有当文件完全为空的时候，才能够删除。日志文件比较复杂，需要截断日志或者备份日志才可以。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">DATABASE</span> 数据库名称</span><br><span class="line">REMOVE <span class="keyword">FILE</span> 文件名</span><br></pre></td></tr></table></figure></p><h2 id="分离和附加数据库"><a href="#分离和附加数据库" class="headerlink" title="分离和附加数据库"></a>分离和附加数据库</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;创建和维护数据库&quot;&gt;&lt;a href=&quot;#创建和维护数据库&quot; class=&quot;headerlink&quot; title=&quot;创建和维护数据库&quot;&gt;&lt;/a&gt;创建和维护数据库&lt;/h1&gt;&lt;p&gt;数据库中的一些概念之间的关系如以下的思维导图：&lt;br&gt;&lt;img src=&quot;https://i
      
    
    </summary>
    
      <category term="数据库技术" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="数据库" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="数据库操作" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>什么是数据化运营</title>
    <link href="http://yoursite.com/2018/03/01/%E6%95%B0%E6%8D%AE%E5%8C%96%E8%BF%90%E8%90%A5%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <id>http://yoursite.com/2018/03/01/数据化运营的基础知识/</id>
    <published>2018-03-01T09:49:59.000Z</published>
    <updated>2018-03-01T11:35:53.727Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-1-现代营销理论的发展"><a href="#1-1-现代营销理论的发展" class="headerlink" title="1.1 现代营销理论的发展"></a>1.1 现代营销理论的发展</h1><h2 id="4P到4C"><a href="#4P到4C" class="headerlink" title="4P到4C"></a>4P到4C</h2><p>4P指product、Price、Place、Promotion。<br>product：产品注重功能，强调卖点。<br>price：价格需要根据不同的市场定位。<br>place：渠道注重分销商的培养和销售网络的建设。<br>promotion：企业通过改变销售行为来刺激消费，以短期的行为促进消费增长。</p><p>4P理论的核心是Product。</p><p>随着时代的发展，商品丰富起来，市场竞争也日益激烈。在21实际消费者成为了商业的核心。<br>这时4C理论兴起。<br>4C是指consumer、cost、communication、convenience。<br>consumer：是指消费者的需求和欲望。<br>cost：是指消费者得到满足的成本。<br>communication：是指与用户的沟通。<br>convenience：是指用户购买的方便性。</p><p>4C理论的核心是消费者。</p><h2 id="4C到3P3C"><a href="#4C到3P3C" class="headerlink" title="4C到3P3C"></a>4C到3P3C</h2><p>大数据时代的来临，4C理论再次落后于时代发展的需求，海量数据的堆积和存储等迫使现代企业不得不寻找更适合、更可控、更可量化的营销思路和方法论。<br>3P3C的六要素：<br>Probability：营销、运营活动以概率为核心，追求精细化和精准率。<br>Product：产品<br>prospect：目标用户<br>Creative：创新<br>Channel：渠道<br>Cost：成本</p><p>数据分析挖掘所支撑的<strong>目标响应概率</strong>是核心。<br>这里的目标响应概率不应狭义理解为仅仅是预测响应模型之类的响应概率，它有更加宽泛的含义。<br>从宏观上理解，概率可以是特定消费者整体上的概率或可能性。比如，我们用卡方检验某个特定的类别的消费群体在某一个消费行为指标上具有显著性特征。<br>从微观上理解，概率可以具体到某一个特定消费者的“预期响应概率”，比如用逻辑回归算法搭建一预测响应模型，得到每个用户的预计响应概率。</p><h1 id="数据化运营的主要内容"><a href="#数据化运营的主要内容" class="headerlink" title="数据化运营的主要内容"></a>数据化运营的主要内容</h1><p>数据化运营业内没有统一的定义，但是其基本要素和核心是一致的，那就是:“<strong>以企业级海量数据的存储和挖掘应用为核心支持，企业全员参与的，以精准、细分和精细化为特点的企业运营制度和战略</strong>。”</p><p>浅层次的理解的话，就是在企业常规运营的基础上革命性地增添数据分析和挖掘的精准支持。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-1-现代营销理论的发展&quot;&gt;&lt;a href=&quot;#1-1-现代营销理论的发展&quot; class=&quot;headerlink&quot; title=&quot;1.1 现代营销理论的发展&quot;&gt;&lt;/a&gt;1.1 现代营销理论的发展&lt;/h1&gt;&lt;h2 id=&quot;4P到4C&quot;&gt;&lt;a href=&quot;#4P到4
      
    
    </summary>
    
      <category term="数据分析" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="数据化化运营" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%8C%96%E5%8C%96%E8%BF%90%E8%90%A5/"/>
    
      <category term="营销" scheme="http://yoursite.com/tags/%E8%90%A5%E9%94%80/"/>
    
  </entry>
  
  <entry>
    <title>MySQL数据导入</title>
    <link href="http://yoursite.com/2018/02/25/MySQLL%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5/"/>
    <id>http://yoursite.com/2018/02/25/MySQLL数据导入/</id>
    <published>2018-02-25T07:29:00.000Z</published>
    <updated>2018-02-25T08:25:14.722Z</updated>
    
    <content type="html"><![CDATA[<p>在安装完MySQL数据库后，数据库中的数据呈现最初始的状态，所以需要向其中填充数据，但是这是数据准备阶段的工作。下面简单介绍一下：</p><h1 id="构建数据库和table"><a href="#构建数据库和table" class="headerlink" title="构建数据库和table"></a>构建数据库和table</h1><ol><li>首先需要进入数据库。在管理员命令窗口输入<code>net start mysql5.7.21</code>。</li><li><p>然后再登陆mysql。</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">mysql -u root -p</span></span><br></pre></td></tr></table></figure></li><li><p>进入后再创建database。</p><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DATABASE test2 <span class="meta">#默认是以utf8编码</span></span><br></pre></td></tr></table></figure></li><li><p>进入test2这个<strong>database中</strong>。</p><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> test2</span><br></pre></td></tr></table></figure></li><li><p>再进行CSV文件的导入。以table的形式。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> TEST_BOOKS1(</span><br><span class="line">      team_name <span class="built_in">varchar</span>(<span class="number">100</span>),</span><br><span class="line">      Wins <span class="built_in">int</span>,</span><br><span class="line">      Draws <span class="built_in">int</span>,</span><br><span class="line">      Losses <span class="built_in">int</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure></li></ol><p>创建table的格式如下：<code>变量名 类型 限制</code><br>以上的实例就是我的表格结构的概括，可以根据自己的需求自行修改参数：<br><img src="https://i.imgur.com/Qb8LePJ.png" alt=""></p><h1 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h1><h2 id="导入"><a href="#导入" class="headerlink" title="导入"></a>导入</h2><p>将自己文件里的数据导入到这个构造好的table中。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">LOAD</span> <span class="keyword">DATA</span> <span class="keyword">INFILE</span> <span class="string">'C:\Users\diannao\Desktop\2015-16-premier-league.csv'</span></span><br><span class="line"><span class="keyword">INTO</span> <span class="keyword">TABLE</span> TEST_BOOKS1</span><br><span class="line"><span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">','</span></span><br><span class="line"><span class="keyword">ENCLOSED</span> <span class="keyword">BY</span> <span class="string">'"'</span></span><br><span class="line"><span class="keyword">LINES</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\n'</span></span><br><span class="line">IGONRE <span class="number">1</span> <span class="keyword">ROWS</span>;</span><br></pre></td></tr></table></figure></p><h2 id="错误解决"><a href="#错误解决" class="headerlink" title="错误解决"></a>错误解决</h2><p>这里需要提一下，如果运行不成功，并且显示的错误是secure-file-priv有问题，那么就需要在my.ini文件中的[mysqld]下进行声明<code>secure-file-priv=</code>,这里的意思就是对于导入和导出不去进行干扰。注意，声明完成后，还需要在管理员命令窗口下对mysql5.7.21进行重启，才能有效。</p><h2 id="检验"><a href="#检验" class="headerlink" title="检验"></a>检验</h2><p>检验的方法<code>SELECT * FROM TEST_BOOKS1</code><br><img src="https://i.imgur.com/YaAxHeD.png" alt=""><br>到这里就算导入成功了！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在安装完MySQL数据库后，数据库中的数据呈现最初始的状态，所以需要向其中填充数据，但是这是数据准备阶段的工作。下面简单介绍一下：&lt;/p&gt;
&lt;h1 id=&quot;构建数据库和table&quot;&gt;&lt;a href=&quot;#构建数据库和table&quot; class=&quot;headerlink&quot; titl
      
    
    </summary>
    
      <category term="数据库" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="MySQL" scheme="http://yoursite.com/tags/MySQL/"/>
    
      <category term="数据准备" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87/"/>
    
  </entry>
  
  <entry>
    <title>MySQL安装与配置</title>
    <link href="http://yoursite.com/2018/02/24/MySQL%E5%AE%89%E8%A3%85/"/>
    <id>http://yoursite.com/2018/02/24/MySQL安装/</id>
    <published>2018-02-24T11:47:01.000Z</published>
    <updated>2018-02-25T02:51:15.368Z</updated>
    
    <content type="html"><![CDATA[<p>我们首先可以在<a href="https://dev.mysql.com/downloads/mysql/" target="_blank" rel="noopener">Mysql的官网</a>上找到我们的需要下载的文件。选择符合自己电脑的版本。</p><p><img src="https://i.imgur.com/rXpNNFo.png" alt=""></p><p>这些都是不需要安装的压缩包，这里就讲一下怎么用这个压缩包安装。</p><ol><li>解压文件，在文件里添加初始化文件<strong>my.ini</strong>。先新建txt文档然后再更名为my.ini。<br><img src="https://i.imgur.com/i9ktpSH.png" alt=""><br>在此文档里添加一段初始化的代码。<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[mysql]</span><br><span class="line"><span class="comment">#设置mysql客户端默认字符集</span></span><br><span class="line"><span class="attribute">default-character-set</span>=utf8</span><br><span class="line">[mysqld]</span><br><span class="line"><span class="comment">#设置3306端口</span></span><br><span class="line"><span class="attribute">port</span>=3306</span><br><span class="line"><span class="comment">#设置mysql的安装目录</span></span><br><span class="line"><span class="attribute">basedir</span>=D:\Program Files\mysql-5.7.21-winx64</span><br><span class="line"><span class="comment">#设置mysql数据库的数据库的存放目录</span></span><br><span class="line"><span class="attribute">datadir</span>=D:\Program Files\mysql-5.7.21-winx64\data</span><br><span class="line"><span class="comment">#允许最大连接数</span></span><br><span class="line">max_connections = 200</span><br><span class="line"><span class="comment">#服务端使用的字符集默认为8比特的latin1字符集</span></span><br><span class="line"><span class="attribute">character-set-server</span>=utf8</span><br><span class="line"><span class="comment">#开启查询缓存</span></span><br><span class="line">explicit_defaults_for_timestamp = <span class="literal">true</span></span><br><span class="line">skip-grant-tables</span><br><span class="line"><span class="comment">#创建新表将使用的默认存储引擎</span></span><br><span class="line"><span class="attribute">default-storage-engine</span>=INNODB</span><br></pre></td></tr></table></figure></li></ol><p>需要注意的是：上面第二个【】里是mysqld。</p><ol><li><p>配置系统变量。在系统变量里添加MYSQL_HOME,路径填你解压文件所在的目录下，我的是<strong>D:\Program Files\mysql-5.7.21-winx64</strong>。然后在系统path里添加：<strong>%MYSQL_HOME%\bin</strong>。</p></li><li><p>以管理员身份运行命令终端cmd。执行一下代码：</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">d:</span><br><span class="line"><span class="keyword">cd</span> *D:\Program Files\mysql-5.7.21-winx64\bin</span><br><span class="line">mysqld <span class="params">--initialize</span> <span class="params">--user=mysql</span> <span class="params">--console</span></span><br></pre></td></tr></table></figure></li><li><p>安装服务。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">mysqld</span> <span class="selector-tag">--install</span> <span class="selector-tag">MySQL5</span><span class="selector-class">.7</span><span class="selector-class">.21</span></span><br></pre></td></tr></table></figure></li><li><p>启动服务。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">net</span> <span class="selector-tag">start</span> <span class="selector-tag">MySQL5</span><span class="selector-class">.7</span><span class="selector-class">.21</span></span><br></pre></td></tr></table></figure></li><li><p>修改密码。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> <span class="keyword">password</span> <span class="keyword">for</span> root@<span class="keyword">local</span>=<span class="keyword">password</span>(<span class="string">'你的密码'</span>)</span><br></pre></td></tr></table></figure></li></ol><p>每次登陆mysql，就输入<br><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">mysql -u root -p</span></span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;我们首先可以在&lt;a href=&quot;https://dev.mysql.com/downloads/mysql/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Mysql的官网&lt;/a&gt;上找到我们的需要下载的文件。选择符合自己电脑的版本。&lt;/p&gt;
&lt;p&gt;&lt;img
      
    
    </summary>
    
      <category term="数据库" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="MySQL" scheme="http://yoursite.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>利用Python进行数据分析之Pandas</title>
    <link href="http://yoursite.com/2018/02/21/%E5%88%A9%E7%94%A8Python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BPandas/"/>
    <id>http://yoursite.com/2018/02/21/利用Python进行数据分析之Pandas/</id>
    <published>2018-02-21T06:19:56.000Z</published>
    <updated>2018-02-21T10:40:33.319Z</updated>
    
    <content type="html"><![CDATA[<p>2008年开始就有pandas库，构建者构造它的原因就是没有任何一个工具可以满足他的工作需求。</p><ul><li>具备按轴自动或显示数据的对齐的功能的数据结构。</li><li>集成时间序列功能。</li><li>既能处理时间序列数据也能处理非时间序列数据的数据结构。</li><li>数据运算和约简可以根据不同的元素数据执行。</li><li>灵活处理缺失数据</li><li>合并及其他出现在常见数据库中的关系型运算。</li></ul><p>我</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;2008年开始就有pandas库，构建者构造它的原因就是没有任何一个工具可以满足他的工作需求。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;具备按轴自动或显示数据的对齐的功能的数据结构。&lt;/li&gt;
&lt;li&gt;集成时间序列功能。&lt;/li&gt;
&lt;li&gt;既能处理时间序列数据也能处理非时间序列数据的数据
      
    
    </summary>
    
      <category term="python工具" scheme="http://yoursite.com/categories/python%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="Pandas" scheme="http://yoursite.com/tags/Pandas/"/>
    
  </entry>
  
  <entry>
    <title>利用Python进行数据分析之IPython</title>
    <link href="http://yoursite.com/2018/02/20/%E5%88%A9%E7%94%A8Python%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    <id>http://yoursite.com/2018/02/20/利用Python进行数据分析/</id>
    <published>2018-02-20T06:58:03.000Z</published>
    <updated>2018-02-21T06:23:58.561Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ipython"><a href="#ipython" class="headerlink" title="ipython"></a>ipython</h1><p><strong>ipython外加一个文本编辑器</strong>是较好的Python开发环境。当然，一款IDE也是不错的选择，但是有些IDE本身就是集成了IPython。</p><p>IPython本身并没有提供任何的计算和数据分析的功能，其主要目地就是在交互式计算和软件开发这两个方面最大化的提高生产力。他鼓励的是“<strong>执行 探索</strong>”的工作模式，而不是许多变成语言那种“编辑 编译 运行”的传统模式。</p><h2 id="python基础"><a href="#python基础" class="headerlink" title="python基础"></a>python基础</h2><p>启动就像标准的Python解释器那样输入ipython即可进入。<br><figure class="highlight vhdl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\diannao</span><br><span class="line">λ ipython</span><br><span class="line">Python <span class="number">3.6</span>.<span class="number">3</span> |Anaconda custom (<span class="number">64</span>-<span class="built_in">bit</span>)| (<span class="keyword">default</span>, Oct <span class="number">15</span> <span class="number">2017</span>, <span class="number">03</span>:<span class="number">27</span>:<span class="number">45</span>) [MSC v.<span class="number">1900</span> <span class="number">64</span> <span class="built_in">bit</span> (AMD64)]</span><br><span class="line"><span class="keyword">Type</span> <span class="symbol">'copyright</span>', <span class="symbol">'credits</span>' <span class="keyword">or</span> <span class="symbol">'license</span>' <span class="keyword">for</span> more information</span><br><span class="line">IPython <span class="number">6.1</span>.<span class="number">0</span> <span class="comment">-- An enhanced Interactive Python. Type '?' for help.</span></span><br></pre></td></tr></table></figure></p><p>注意的是Python对象都被格式化的可读性很好，和print的输出形式有着显著的区别。</p><p><img src="https://i.imgur.com/U3bmXhW.png" alt=""></p><p><img src="https://i.imgur.com/4eDeIEw.png" alt=""></p><h2 id="Tab键自动填充"><a href="#Tab键自动填充" class="headerlink" title="Tab键自动填充"></a>Tab键自动填充</h2><p>在shell中输入表达式时，只要按下Tab键，当前命名空间只要有与输入的字符串相匹配的变量就会被找出：<br><img src="https://i.imgur.com/nSXyZRI.png" alt=""><br>而且还可以用在任何对象后面以及模块后面：<br><img src="https://i.imgur.com/Uw9aKTM.png" alt=""></p><p>据说还可以填充路径字符串，本人无法成功，原因不明。</p><h2 id="内省"><a href="#内省" class="headerlink" title="内省"></a>内省</h2><p>可以显示命名空间的信对象信息，以及函数的信息（一个问号会显示docstring，连个问号会显示整个函数的源代码）。<br><img src="https://i.imgur.com/Ne6uMej.png" alt=""></p><p><img src="https://i.imgur.com/Ysabq37.png" alt=""></p><p><img src="https://i.imgur.com/mvJskMN.png" alt=""></p><p>还可以作为正则表达式中去匹配：</p><p><img src="https://i.imgur.com/FuruaTS.png" alt=""></p><h2 id="run命令"><a href="#run命令" class="headerlink" title="%run命令"></a>%run命令</h2><p>用来执行脚本文件。<br><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%<span class="keyword">run</span><span class="bash"> 文件名.py</span></span><br></pre></td></tr></table></figure></p><p>执行之后就可以在ipython shell中运用脚本里的全局变量、函数、模块等等。</p><h2 id="执行剪切板中的代码"><a href="#执行剪切板中的代码" class="headerlink" title="执行剪切板中的代码"></a>执行剪切板中的代码</h2><p>利用%paste和%cpaste。%paste是直接复制后立即执行，%cpaste可以对此复制，方法是键入%cpaste后再点击右键会有提示，不停的在剪切板中添加新的元素就可以不断的复制粘贴，最后输入–，如果发现不对就输入Ctrl-c。</p><h2 id="键盘快捷键"><a href="#键盘快捷键" class="headerlink" title="键盘快捷键"></a>键盘快捷键</h2><ul><li>Ctrl-A  将光标移动到行首</li><li>Ctrl-E  将光标移动到行尾</li><li>Ctrl-K  删除从光标开始至行尾的文本</li><li>Ctrl-U  清除当前行的所有文本</li><li>Ctrl-L  清屏</li></ul><h2 id="魔术命令"><a href="#魔术命令" class="headerlink" title="魔术命令"></a>魔术命令</h2><ul><li>%quickref  显示IPython的快速参考</li><li>%magic     显示所有魔术命令的详细文档</li><li>%debug     从最新的异常跟踪的底端进入交互式调试</li><li>%hist      打印命令的输入历史</li><li>%pdb       在异常发生后自动进入调试器</li><li>%time      报告某段程序执行时间</li><li>%timeit    多次执行某段程序，计算系综平均执行时间，对执行时间非常小的代码很有用。</li><li>%xdel variable 删除variable，并清除一切引用。</li></ul><h2 id="基于Qt的富GUI控制台"><a href="#基于Qt的富GUI控制台" class="headerlink" title="基于Qt的富GUI控制台"></a>基于Qt的富GUI控制台</h2><p>安装了PyQt或Pyside，输入<code>ipython qtconsole --pylab=inline</code><br>这里我的版本是比较新的运行会出现警告，输入<code>juyter qtconsole</code>就行。</p><h2 id="matplotlib集成与pylab模式"><a href="#matplotlib集成与pylab模式" class="headerlink" title="matplotlib集成与pylab模式"></a>matplotlib集成与pylab模式</h2><p>输入<code>ipython --pylab</code></p><h2 id="使用命令历史"><a href="#使用命令历史" class="headerlink" title="使用命令历史"></a>使用命令历史</h2><p>ipython维护这一个小型的数据库，其中包含你执行过程中每条命令文本。</p><h3 id="搜索并重用命令历史"><a href="#搜索并重用命令历史" class="headerlink" title="搜索并重用命令历史"></a>搜索并重用命令历史</h3><p>按住上或下（或者Ctrl-P或Ctrl-N）你就可以搜索你之前输入过的命令。</p><p>输入之前命令的部分字符再按住Crtl-R就能跳出与其匹配的命令。</p><h3 id="输入变量和输出变量"><a href="#输入变量和输出变量" class="headerlink" title="输入变量和输出变量"></a>输入变量和输出变量</h3><p>忘记把函数赋值给变量很让人郁闷，ipython会将一些输入和输出的引用保存在一些特殊的变量里，<strong>最近的两个输出</strong>结果分别保存在_和__中。</p><p>输入文本被保存在名为_ix的变量中，其中x代表行号，<br>对应的输入变量被保存_x中，x的意义一样。<br><code>exec _ix</code>可以执行命令。<br><code>%xdel</code>和<code>%reset</code>可以解决释放内存不成功的问题。</p><h2 id="与操作系统的交互"><a href="#与操作系统的交互" class="headerlink" title="与操作系统的交互"></a>与操作系统的交互</h2><ul><li>%bookmark        使用ipython的目录书签系统</li><li>%cd directory    将系统工作目录更改为书签系统</li><li>%pwd             返回系统的当前工作目录</li><li>%push directory  将当前目录压入堆栈，并转向目标目录</li><li>%poped           弹出栈顶目录，并转向目该目录</li><li>%dirs            返回一个含有当前目录栈的列表</li></ul><h3 id="shell命令和别名"><a href="#shell命令和别名" class="headerlink" title="shell命令和别名"></a>shell命令和别名</h3><p>以感叹号开头的命令行表示其后的所有内容需要在shell中执行。比如：<br><code>!ipython</code>可以从ipython中退出然后进入到python标准交互系统中。<br>还可以用<code>%alias 别名 命令</code>来为别名自定义别名，不过这是暂时的。</p><h3 id="目录书签系统"><a href="#目录书签系统" class="headerlink" title="目录书签系统"></a>目录书签系统</h3><p>输入<code>%bookmark db 目录</code>就可以将目录用db来取代，下次直接输入<code>cd db</code>就能进入刚才你输入的目录。</p><h2 id="IPython-HTML-Notebook"><a href="#IPython-HTML-Notebook" class="headerlink" title="IPython HTML Notebook"></a>IPython HTML Notebook</h2><p>在命令行中输入<code>jupyter notebook</code><br>注意这里我的版本，不是以前用的ipython notebook，而且后面也不能随便添加标注–<strong>pylab=inline</strong>，直接在<strong>juyter notebook</strong>中输入%<strong>pylab inline</strong>即可。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;ipython&quot;&gt;&lt;a href=&quot;#ipython&quot; class=&quot;headerlink&quot; title=&quot;ipython&quot;&gt;&lt;/a&gt;ipython&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;ipython外加一个文本编辑器&lt;/strong&gt;是较好的Python开发环境。当然
      
    
    </summary>
    
      <category term="python工具" scheme="http://yoursite.com/categories/python%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="数据分析" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>module安装问题</title>
    <link href="http://yoursite.com/2018/01/29/module%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2018/01/29/module安装问题/</id>
    <published>2018-01-29T06:00:39.000Z</published>
    <updated>2018-01-29T06:21:39.215Z</updated>
    
    <content type="html"><![CDATA[<p>前言：由于我为了方便，开始就安装了Anaconda，所以很多模块都已经装好了，遇到没有的模块，我们可以用pip install +模块名字，但是有的时候也会出现问题。</p><h1 id="wordcloud安装出错"><a href="#wordcloud安装出错" class="headerlink" title="wordcloud安装出错"></a>wordcloud安装出错</h1><p>你会发现在cmd的输入命令 <code>pip install wordcloud</code> 时会报错。<br><strong>解决方法</strong>：</p><p>在以下这个网址<br><a href="http://link.zhihu.com/?target=http%3A//www.lfd.uci.edu/%7Egohlke/pythonlibs/%23lxml" target="_blank" rel="noopener">http://link.zhihu.com/?target=http%3A//www.lfd.uci.edu/%7Egohlke/pythonlibs/%23lxml</a><br>下载你需要的的对应版本模块。</p><p><img src="https://i.imgur.com/WIuFEGl.png" alt=""></p><p>接着，把下载下来的文件原封不动的拷贝到你pyhon或者Anaconda的Scripts中，我的就是F:\Anaconda\Scripts</p><p>再到cmd中执行pip install F:\Anaconda\Scripts\刚才的文件名</p><p>这样就能下载成功！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前言：由于我为了方便，开始就安装了Anaconda，所以很多模块都已经装好了，遇到没有的模块，我们可以用pip install +模块名字，但是有的时候也会出现问题。&lt;/p&gt;
&lt;h1 id=&quot;wordcloud安装出错&quot;&gt;&lt;a href=&quot;#wordcloud安装出错&quot; c
      
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="模块安装" scheme="http://yoursite.com/tags/%E6%A8%A1%E5%9D%97%E5%AE%89%E8%A3%85/"/>
    
  </entry>
  
  <entry>
    <title>python爬虫（3）</title>
    <link href="http://yoursite.com/2018/01/26/python%E7%88%AC%E8%99%AB%EF%BC%883%EF%BC%89/"/>
    <id>http://yoursite.com/2018/01/26/python爬虫（3）/</id>
    <published>2018-01-26T14:25:49.000Z</published>
    <updated>2018-03-07T10:51:08.582Z</updated>
    
    <content type="html"><![CDATA[<p>之前的两节，我们把我们要的东西爬取下来，但是并没有做存储，下面我们将会讲解如何做存储。</p><h2 id="保存到Excel"><a href="#保存到Excel" class="headerlink" title="保存到Excel"></a>保存到Excel</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line">df = pandas.DataFrame(final)</span><br><span class="line">df.to_excel(<span class="string">'news.xlsx'</span>)</span><br></pre></td></tr></table></figure><p>这是就可以在我们的目录当中找到news.xlsx的文件。</p><h2 id="保存到数据库"><a href="#保存到数据库" class="headerlink" title="保存到数据库"></a>保存到数据库</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line"><span class="keyword">with</span> sqlite3.connect(<span class="string">'news.sqlite'</span>) <span class="keyword">as</span> db:</span><br><span class="line">    df.to_sql(<span class="string">'news'</span>,con = db)</span><br></pre></td></tr></table></figure><p>可以利用pandas去sqlite中拿数据：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> sqlite3.connect(<span class="string">'news.sqlite'</span>) <span class="keyword">as</span> db:</span><br><span class="line">    df2 = pandas.read_sql(<span class="string">'SELECT * FROM news'</span>,con = db)</span><br></pre></td></tr></table></figure></p><p>连上钱两次，就算是一个完整的爬虫过程了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;之前的两节，我们把我们要的东西爬取下来，但是并没有做存储，下面我们将会讲解如何做存储。&lt;/p&gt;
&lt;h2 id=&quot;保存到Excel&quot;&gt;&lt;a href=&quot;#保存到Excel&quot; class=&quot;headerlink&quot; title=&quot;保存到Excel&quot;&gt;&lt;/a&gt;保存到Excel&lt;/h
      
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="爬虫" scheme="http://yoursite.com/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="数据库" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>python爬虫（2）</title>
    <link href="http://yoursite.com/2018/01/26/%E7%88%AC%E8%99%AB%EF%BC%882%EF%BC%89/"/>
    <id>http://yoursite.com/2018/01/26/爬虫（2）/</id>
    <published>2018-01-26T03:48:14.000Z</published>
    <updated>2018-03-07T11:21:40.458Z</updated>
    
    <content type="html"><![CDATA[<p>事前的章节只是负责把新闻的网页爬取下来，对于内文的需求还是不够的，所以这篇文章主要讲的是对于内文信息的爬取，包括<strong>标题、时间、作者、来源</strong>等等。</p><p>还和之前的爬去方法一样，利用<strong>Chrome F12</strong>就可以找到网页和获取响应的方法，之前有讲过。代码如下：<br><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">from bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">res = requests.get(<span class="string">"http://news.sina.com.cn/o/2018-01-26/doc-ifyqyesy2133291.shtml"</span>)</span><br><span class="line">res.encoding = <span class="string">'utf-8'</span></span><br><span class="line">soup = BeautifulSoup(res.<span class="keyword">text</span>,<span class="string">'html.parser'</span>)</span><br></pre></td></tr></table></figure></p><p>这样就获取了我们所需要的网页部分，继续进行标签的搜寻。</p><ol><li>标题。在class=“main-title”的标签之中。</li><li>时间。在class=“date-source”中，但是都在span标签下，可以用contents将不同分层的标签下的东西取出。最后用datetime模块将<strong>时间字符串</strong>变成<strong>时间格式</strong>。</li><li>来源。和上面类似的操作。</li><li>内容。找到后会有分段的内容，利用<strong>for循环</strong>嵌套后就可以取出来，再用<strong>join</strong>连接成一个完整的部分。</li><li>评论数。你在doc中找不到，它在js中，而且还需要用json模块将数据变成我们容易处理的字典。<br>具体代码如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">title = soup.select(<span class="string">'.main-title'</span>)[<span class="number">0</span>].text</span><br><span class="line">date = soup.select(<span class="string">'.date-source'</span>)[<span class="number">0</span>].contents[<span class="number">1</span>].text</span><br><span class="line">dt = datetime.strptime(date,<span class="string">'%Y年%m月%d日 %H:%M'</span>)</span><br><span class="line">source = soup.select(<span class="string">'.date-source a '</span>)[<span class="number">0</span>].text</span><br><span class="line">body = soup.select(<span class="string">'.article p'</span>)[:<span class="number">-1</span>]</span><br><span class="line">article = <span class="string">'\n'</span>.join([d.text.strip() <span class="keyword">for</span> d <span class="keyword">in</span> body])</span><br><span class="line">mport json</span><br><span class="line">comment = requests.get(<span class="string">'http://comment5.news.sina.com.cn/page/info?version=1&amp;format=json&amp;\</span></span><br><span class="line"><span class="string">channel=gn&amp;newsid=comos-fyqyesy2133291&amp;\</span></span><br><span class="line"><span class="string">group=undefined&amp;compress=0&amp;ie=utf-8&amp;oe=utf-8&amp;page=1&amp;page_size=3&amp;t_size=3&amp;\</span></span><br><span class="line"><span class="string">h_size=3&amp;thread=1&amp;callback=jsonp_1516947697495&amp;_=1516947697495'</span>)</span><br><span class="line">jd = json.loads(comment.text.lstrip(<span class="string">'jsonp_1516947697495('</span>).rstrip(<span class="string">')'</span>))</span><br><span class="line">jd[<span class="string">'result'</span>][<span class="string">'count'</span>][<span class="string">'total'</span>]</span><br></pre></td></tr></table></figure></li></ol><p>评论数的获取页面链接中包含新闻<strong>id</strong>，在新闻本身的页面链接能找到。将它独立取出的方法有两个：</p><ol><li><p>用<strong>split</strong>将链接变成多个块组成的list，然后再用索引取，最后用<strong>strip</strong>削掉我们不要的部分。</p><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span><span class="type">url</span> = <span class="string">'http://news.sina.com.cn/o/2018-01-26/doc-ifyqyesy2133291.shtml'</span></span><br><span class="line"><span class="keyword">new</span><span class="type">sid</span> = <span class="keyword">new</span><span class="type">url</span>.split(<span class="string">'/'</span>)[<span class="number">-1</span>].lstrip(<span class="string">'doc-i'</span>).rstrip(<span class="string">'.shtml'</span>)</span><br></pre></td></tr></table></figure></li><li><p>利用正则表达去匹配。</p><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re </span><br><span class="line">m = re.search(<span class="string">'doc-i(.*).shtml'</span>,<span class="keyword">new</span><span class="type">url</span>)</span><br><span class="line">m.group(<span class="number">1</span>)</span><br></pre></td></tr></table></figure></li></ol><p>当然这是一个页面的评论数，写一个函数就能解决。利用<strong>字符串的format</strong>把上面获得的字符串填入大家共同的部分中。<br><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re </span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">commenturl = <span class="string">'http://comment5.news.sina.com.cn/page/info?version=1&amp;format=json&amp;\</span></span><br><span class="line"><span class="string">channel=gn&amp;newsid=comos-&#123;&#125;&amp;\</span></span><br><span class="line"><span class="string">group=undefined&amp;compress=0&amp;ie=utf-8&amp;oe=utf-8&amp;page=1&amp;page_size=3&amp;t_size=3&amp;\</span></span><br><span class="line"><span class="string">h_size=3&amp;thread=1&amp;callback=jsonp_1516947697495&amp;_=1516947697495'</span></span><br><span class="line">def Getcount(<span class="keyword">new</span><span class="type">url</span>):<span class="type"></span></span><br><span class="line"><span class="type">    m </span>= re.search(<span class="string">'doc-i(.*).shtml'</span>,<span class="keyword">new</span><span class="type">url</span>)</span><br><span class="line">    <span class="keyword">new</span><span class="type">sid</span> = m.group(<span class="number">1</span>)</span><br><span class="line">    comment = requests.<span class="keyword">get</span>(commenturl.format(<span class="keyword">new</span><span class="type">sid</span>))</span><br><span class="line">    jd = json.loads(comment.text.lstrip(<span class="string">'jsonp_1516947697495('</span>).rstrip(<span class="string">')'</span>))</span><br><span class="line">    <span class="keyword">return</span> jd[<span class="string">'result'</span>][<span class="string">'count'</span>][<span class="string">'total'</span>]</span><br></pre></td></tr></table></figure></p><p>将上面汇总成一个函数中，通过字典返回我们要的所有内文细节：<br><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">from bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re </span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">def News(newurl):</span><br><span class="line">    article = &#123;&#125;</span><br><span class="line">    res = requests.get(newurl)</span><br><span class="line">    res.encoding = <span class="string">'utf-8'</span></span><br><span class="line">    soup = BeautifulSoup(res.<span class="keyword">text</span>,<span class="string">'html.parser'</span>)</span><br><span class="line">    article[<span class="string">'title'</span>] = soup.select(<span class="string">'.main-title'</span>)[<span class="number">0</span>].<span class="keyword">text</span></span><br><span class="line">    date = soup.select(<span class="string">'.date-source'</span>)[<span class="number">0</span>].<span class="built_in">contents</span>[<span class="number">1</span>].<span class="keyword">text</span></span><br><span class="line">    article[<span class="string">'dt'</span>] = datetime.strptime(date,<span class="string">'%Y年%m月%d日 %H:%M'</span>)</span><br><span class="line">    article[<span class="string">'source'</span>] = soup.select(<span class="string">'.date-source a '</span>)[<span class="number">0</span>].<span class="keyword">text</span></span><br><span class="line">    body = soup.select(<span class="string">'.article p'</span>)[:-<span class="number">1</span>]</span><br><span class="line">    article[<span class="string">'articleBody'</span>] = <span class="string">'\n'</span>.join([d.<span class="keyword">text</span>.strip() <span class="keyword">for</span> d <span class="built_in">in</span> body])</span><br><span class="line">    article[<span class="string">'author'</span>] = soup.select(<span class="string">'.show_author'</span>)[<span class="number">0</span>].<span class="keyword">text</span>.lstrip(<span class="string">'责任编辑：'</span>)</span><br><span class="line">    article[<span class="string">'commentcount'</span>] = Getcount(newurl)</span><br><span class="line">    return article</span><br></pre></td></tr></table></figure></p><p>这里定义了一个网页链可以得到的所有内容信息，接下来就是考虑一个页面上的所有网页链接都爬下来。主要是通过在<strong>js中找到不同步的分页信息</strong>才得以了解所有的网页链接是什么。代码如下：<br><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def parserlist(url): <span class="type"></span></span><br><span class="line"><span class="type">    newdetails </span>= []</span><br><span class="line">    res = requests.<span class="keyword">get</span>(url)</span><br><span class="line">    <span class="keyword">new</span><span class="type">urlnot</span> = res.text.lstrip(<span class="string">'  newsloadercallback('</span>).rstrip(<span class="string">');'</span>)</span><br><span class="line">    jd = json.loads(<span class="keyword">new</span><span class="type">urlnot</span>)</span><br><span class="line">    <span class="keyword">for</span> d <span class="keyword">in</span> jd[<span class="string">'result'</span>][<span class="string">'data'</span>]:<span class="type"></span></span><br><span class="line"><span class="type">        newdetails</span>.append(News(d[<span class="string">'url'</span>]))</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span><span class="type">details</span></span><br></pre></td></tr></table></figure></p><p><strong>parserlist</strong>函数唯一的输入参数就是那个<strong>js</strong>中的网页连接（管理着一个页面的的所有新闻链接）</p><p>但是问题又来了，我们的分页可不止一个，所以我们继续观察分页的网页链接，发现page={数字}表示页数，那么我们可以写一个函数继续扩大工作量。代码如下：<br><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">url = 'http://api.roll.news.sina.com.cn/zt_list?channel=news&amp;cat_1=gnxw&amp;cat_2==gdxw1|<span class="type">|=gatxw</span>|<span class="type">|=zs</span>-pl|<span class="type">|=mtjj</span>&amp;level==<span class="number">1</span>|<span class="type">|=2</span>&amp;show_ext=<span class="number">1</span>&amp;show_all=<span class="number">1</span>&amp;show_num=<span class="number">22</span>&amp;tag=<span class="number">1</span>&amp;format=json&amp;page=&#123;&#125;&amp;callback=newsloadercallback&amp;<span class="keyword">_</span>=<span class="number">1516960730249</span>'</span><br><span class="line">final = []</span><br><span class="line"><span class="keyword">for</span> i <span class="built_in">in</span> range(<span class="number">1</span>,<span class="number">10</span>):</span><br><span class="line">    newser = parserlist(url.format(i))</span><br><span class="line">    final.extend(newser)</span><br></pre></td></tr></table></figure></p><p>最终的<strong>final</strong>就是我们要的9个页面的所有新闻内文。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;事前的章节只是负责把新闻的网页爬取下来，对于内文的需求还是不够的，所以这篇文章主要讲的是对于内文信息的爬取，包括&lt;strong&gt;标题、时间、作者、来源&lt;/strong&gt;等等。&lt;/p&gt;
&lt;p&gt;还和之前的爬去方法一样，利用&lt;strong&gt;Chrome F12&lt;/strong&gt;就
      
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="爬虫" scheme="http://yoursite.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>python爬虫（1）</title>
    <link href="http://yoursite.com/2018/01/25/python%E7%88%AC%E8%99%AB/"/>
    <id>http://yoursite.com/2018/01/25/python爬虫/</id>
    <published>2018-01-25T04:07:52.000Z</published>
    <updated>2018-01-25T16:51:07.584Z</updated>
    
    <content type="html"><![CDATA[<p>今天来简单的学习一下爬取网页的文档，然后归档。</p><h1 id="第一个简单的爬虫"><a href="#第一个简单的爬虫" class="headerlink" title="第一个简单的爬虫"></a>第一个简单的爬虫</h1><p>利用<strong>chrome F12</strong>的检查功能对网页的回应进行读取，这里以新浪网为例。</p><p><img src="https://i.imgur.com/HIf2TXK.png" alt=""></p><p><img src="https://i.imgur.com/5xFFPul.png" alt=""></p><p>获取到这些信息后，我们就能够写出一下代码：<br><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">new_url = 'http:<span class="comment">//news.sina.com.cn/society/</span></span><br><span class="line">res = requests.<span class="keyword">get</span>(new_url)</span><br><span class="line">res.encoding = 'utf-<span class="number">8</span>'</span><br><span class="line"><span class="built_in">print</span>(res.text)</span><br></pre></td></tr></table></figure></p><p>打印出来后表明没有问题，这是可以用到BeautifulSoup这个模块，讲刚才打印出来的东西丢进去，交给它处理，注意还需标明剖析器是html.parser。</p><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">soup = BeautifulSoup(res.<span class="keyword">text</span>,<span class="string">'html.parser'</span>)</span><br></pre></td></tr></table></figure><p>我们可以知道，在res里有很多的标签，我们需要的文字藏在固定的标签中，所以我们下面要做的就是取出我们需要的标签，需要用到soup的select方法。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">soup2 = soup.select(<span class="string">'h2'</span>)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(soup2)</span></span></span><br></pre></td></tr></table></figure><p>结果如下，是一个列表。<br><img src="https://i.imgur.com/nYTzwP3.png" alt=""></p><p>但是我们要爬取的内容的标签是以不同的id和class来区分的，这里涉及到css的相关内容，我们暂且不谈。只需要知道我们需要通过网页的<strong>检查</strong>了解我们的新闻藏在什么杨种类的标签之下。</p><p><img src="https://i.imgur.com/W7x0Sz2.png" alt=""></p><p>现在可以知道我们的内容在news-item的class之下，所以我们运用select(‘.news-item’)的方法去获取，同样的方法，我们又可以知道，新闻的标题在<strong>h标签下</strong>，新闻的时间在<strong>值time的class之下</strong>，链接在<strong>h2标签的href中</strong>，写出一下代码。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">soup = BeautifulSoup(res<span class="selector-class">.text</span>,<span class="string">'html.parser'</span>)</span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> soup.select(<span class="string">'.news-item'</span>):</span><br><span class="line">    <span class="keyword">if</span> len(link.select(<span class="string">'h2'</span>)) &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="selector-tag">h2</span> = link.select(<span class="string">'h2'</span>)[<span class="number">0</span>].text</span><br><span class="line">        <span class="selector-tag">time</span> = link.select(<span class="string">'.time'</span>)[<span class="number">0</span>].text</span><br><span class="line">        href = link.select(<span class="string">'a'</span>)[<span class="number">0</span>][<span class="string">'href'</span>]</span><br><span class="line">        print(<span class="selector-tag">time</span>,<span class="selector-tag">h2</span>,href)</span><br></pre></td></tr></table></figure></p><p><strong>注：text取的是标签的文字内容，而[‘href’]取的是标签内部的值。</strong></p><p>最终结果如下：</p><p><img src="https://i.imgur.com/pjSMwDJ.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;今天来简单的学习一下爬取网页的文档，然后归档。&lt;/p&gt;
&lt;h1 id=&quot;第一个简单的爬虫&quot;&gt;&lt;a href=&quot;#第一个简单的爬虫&quot; class=&quot;headerlink&quot; title=&quot;第一个简单的爬虫&quot;&gt;&lt;/a&gt;第一个简单的爬虫&lt;/h1&gt;&lt;p&gt;利用&lt;strong&gt;chrom
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>寒假</title>
    <link href="http://yoursite.com/2018/01/24/%E5%AF%92%E5%81%87/"/>
    <id>http://yoursite.com/2018/01/24/寒假/</id>
    <published>2018-01-23T16:23:03.000Z</published>
    <updated>2018-01-25T16:51:21.557Z</updated>
    
    <content type="html"><![CDATA[<p>我不知道为什么要写这个东西，只是闲着无聊，有不想动笔写日记，反正也没有喜欢的本子，就把闲置的博客拿来用用吧，希望未来自己看到这个能够有所感触。</p><p>我在从南京回来的路上听到一则鼓励写作的的录音，说写作并不用很好好的文笔只需要保持一直写就可以了。对于这个观点，我相信，原因很简单，我没有文笔，又喜欢写点东西，决定坚持。</p><p>我现在懂了，不是只有难得的事情，做出来了才伟大，简单的事情坚持一直做也是件很了不起的。突然想起来我的高中化学课的老师曾经和我们讲过某企业老板要求自己的员工在每天某个时间点准时起来做一分钟的高抬腿，而且他们真正的做到了。一件事，做一天你可能回说没什么，做一周也还好，一个月很厉害，一年也还好，三年四年。。。你会怎么觉得，我看到一则介绍爱情的短视频，<strong>一个男生为自己喜欢的女生每天削一个苹果，坚持了2300天</strong>，他们没有吵过架。</p><p>从此刻开始，我要为了自己想过的生活儿努力，坚持写作，每天。就和每天吃饭睡觉一样。寒假放假之前，我加了一个学习理财的群，我发现，他们一只都在教我们理财的重要性，大家还在学的那么起劲，我再管网几天，看看又没有干货，有没有的话就退出吧。今天看完了爬虫的一段教程，我觉讲的很有条理，明天继续。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;我不知道为什么要写这个东西，只是闲着无聊，有不想动笔写日记，反正也没有喜欢的本子，就把闲置的博客拿来用用吧，希望未来自己看到这个能够有所感触。&lt;/p&gt;
&lt;p&gt;我在从南京回来的路上听到一则鼓励写作的的录音，说写作并不用很好好的文笔只需要保持一直写就可以了。对于这个观点，我相信
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Datastruct</title>
    <link href="http://yoursite.com/2017/12/12/datastruct/"/>
    <id>http://yoursite.com/2017/12/12/datastruct/</id>
    <published>2017-12-12T02:51:57.000Z</published>
    <updated>2018-01-25T16:50:49.224Z</updated>
    
    <content type="html"><![CDATA[<h1 id="线性表"><a href="#线性表" class="headerlink" title="线性表"></a>线性表</h1><h2 id="顺序表示"><a href="#顺序表示" class="headerlink" title="顺序表示"></a>顺序表示</h2><p><strong>DestroyLis</strong>t是将线性表的所有内容释放。线性表有三个属性，分别是线性表的空间基址、当前内容的长度<strong>length</strong>以及分配的长度<strong>size</strong>。（这里分配的长度需要大于内容的长度）<strong>DestroyList</strong>是讲所有的属性抹去初始值。</p><p><strong>ClearList</strong>是将当前的内容长度置0。</p><p><strong>isEmpty</strong>则是通过内容长度来判断线性表是否为空。</p><p><strong>GetElem</strong>是将第i个元素取出来并返回。</p><p><strong>FindElem</strong>是将表中元素与查找元素相同的下标输出。</p><p>对应的还有插入、删除、访问、历遍等等。。。。。</p><h2 id="链式表示"><a href="#链式表示" class="headerlink" title="链式表示"></a>链式表示</h2><p>链式表示和顺序表示最大的不同就是，链式表示中逻辑位置相邻的数据他们需要物理位置也相邻。插入和删除不需要再将大量的数据做移动，减少算法的复杂度。</p><p>定义单链表时会有两个属性，1.数据，2.下一个节点的指针。</p><p>作业，编写代码<strong>实现链表反转和实现一元多项式的相加</strong>。</p><p>12/12/2017 11:46:54 AM </p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;线性表&quot;&gt;&lt;a href=&quot;#线性表&quot; class=&quot;headerlink&quot; title=&quot;线性表&quot;&gt;&lt;/a&gt;线性表&lt;/h1&gt;&lt;h2 id=&quot;顺序表示&quot;&gt;&lt;a href=&quot;#顺序表示&quot; class=&quot;headerlink&quot; title=&quot;顺序表示&quot;&gt;&lt;/a&gt;顺序表
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>考研前的课程复习安排</title>
    <link href="http://yoursite.com/2017/11/27/%E8%80%83%E7%A0%94%E5%89%8D%E7%9A%84%E8%AF%BE%E7%A8%8B%E5%A4%8D%E4%B9%A0%E5%AE%89%E6%8E%92/"/>
    <id>http://yoursite.com/2017/11/27/考研前的课程复习安排/</id>
    <published>2017-11-27T11:37:16.000Z</published>
    <updated>2018-01-25T16:51:34.418Z</updated>
    
    <content type="html"><![CDATA[<p>这学期可能是我大学期间的转折点，也将可能会是我大学阶段面对考试最困难的一个学期，因为我大三了，而且面临考验抉择，所以这个学期志在必得（一门都不许挂），下面是我最低限度的复习计划，针对每天整理出最少的复习量。</p><p><img src="https://i.imgur.com/nQ5pPSQ.jpg" alt=""></p><p>这学期的课程分为6门：通原，通线相对可以接受，交换，信息论，单片机，电磁场很难。</p><p>现在是第13周，距离考试还有4周不到的时间，我暂且粗略的估计是20天，还留七八天用来巩固。</p><h1 id="通原"><a href="#通原" class="headerlink" title="通原"></a>通原</h1><p>一共13章，一天一章，从明天开始。</p><h1 id="通线"><a href="#通线" class="headerlink" title="通线"></a>通线</h1><p>一共10章，一天一章，从明天开始。</p><h1 id="电磁场"><a href="#电磁场" class="headerlink" title="电磁场"></a>电磁场</h1><p>一共8章，一天一章，从明天开始。</p><h1 id="交换机"><a href="#交换机" class="headerlink" title="交换机"></a>交换机</h1><p>一共11章，一天一章，从12月6日开始。</p><h1 id="单片机"><a href="#单片机" class="headerlink" title="单片机"></a>单片机</h1><p>一共11章，一天一章，从12月7日开始。</p><p>#信息论 #<br>一共7章，一天一章，从12月11日开始。</p><p>这些课程除外还有一节毛概，一节通创，一节就业指导，以及一节实验。</p><p>综合起来将会有10门功课，加油吧，就这么多了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这学期可能是我大学期间的转折点，也将可能会是我大学阶段面对考试最困难的一个学期，因为我大三了，而且面临考验抉择，所以这个学期志在必得（一门都不许挂），下面是我最低限度的复习计划，针对每天整理出最少的复习量。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2017/11/23/hello-world/"/>
    <id>http://yoursite.com/2017/11/23/hello-world/</id>
    <published>2017-11-23T15:47:33.091Z</published>
    <updated>2017-11-23T15:47:33.091Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
